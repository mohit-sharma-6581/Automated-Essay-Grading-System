{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automated Essay Grading.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "H4xNAffc4WFt",
        "PjKq4L58qKvz",
        "GRhHvSLs4M5n",
        "GrSAGczY31EN",
        "WSx6-tBT0QdE",
        "k--YqYrTVSnl",
        "_Mu60veu74qG",
        "4uu_8M7gZUiO",
        "nanS4gZYnzpQ"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4xNAffc4WFt"
      },
      "source": [
        "#Libraries*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0ZFNfD1U3UJ",
        "outputId": "2f656871-5b82-4ce7-93a3-69dffcd31a9f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import nltk\n",
        "nltk.download('all')\n",
        "\n",
        "!pip install nbspellcheck\n",
        "from spellchecker import SpellChecker\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from string import punctuation\n",
        "\n",
        "import re,string,unicodedata\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "from nltk.corpus import wordnet, stopwords\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from mlxtend.preprocessing import minmax_scaling\n",
        "\n",
        "import collections\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n",
            "Requirement already satisfied: nbspellcheck in /usr/local/lib/python3.7/dist-packages (0.0.5)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from nbspellcheck) (1.1.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from nbspellcheck) (3.2.5)\n",
            "Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.7/dist-packages (from nbspellcheck) (0.6.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->nbspellcheck) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjKq4L58qKvz"
      },
      "source": [
        "# Connecting to Gdrive*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNA_mmPhcm1Y",
        "outputId": "6218741d-2dac-443c-9000-3a7b2cdf9bd3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_f038x-kn9U",
        "outputId": "e6491251-5eef-4035-988d-a2b11015e54b"
      },
      "source": [
        "%cd /content/gdrive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "c56-gAkHk1RU",
        "outputId": "382b8e3b-8e8c-4768-a00e-00384dd78f57"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLhtCDjlleCR"
      },
      "source": [
        "#ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRhHvSLs4M5n"
      },
      "source": [
        "#Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrTIp-1SllSl"
      },
      "source": [
        "df_train = pd.read_csv('training_set_rel3.tsv', sep='\\t', encoding='ISO-8859-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "0etTaP0Hlrsr",
        "outputId": "01c4da7a-fb9a-465f-a512-76cc4de7b7aa"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>rater3_domain1</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>rater1_domain2</th>\n",
              "      <th>rater2_domain2</th>\n",
              "      <th>domain2_score</th>\n",
              "      <th>rater1_trait1</th>\n",
              "      <th>rater1_trait2</th>\n",
              "      <th>rater1_trait3</th>\n",
              "      <th>rater1_trait4</th>\n",
              "      <th>rater1_trait5</th>\n",
              "      <th>rater1_trait6</th>\n",
              "      <th>rater2_trait1</th>\n",
              "      <th>rater2_trait2</th>\n",
              "      <th>rater2_trait3</th>\n",
              "      <th>rater2_trait4</th>\n",
              "      <th>rater2_trait5</th>\n",
              "      <th>rater2_trait6</th>\n",
              "      <th>rater3_trait1</th>\n",
              "      <th>rater3_trait2</th>\n",
              "      <th>rater3_trait3</th>\n",
              "      <th>rater3_trait4</th>\n",
              "      <th>rater3_trait5</th>\n",
              "      <th>rater3_trait6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set  ... rater3_trait5  rater3_trait6\n",
              "0         1          1  ...           NaN            NaN\n",
              "1         2          1  ...           NaN            NaN\n",
              "2         3          1  ...           NaN            NaN\n",
              "3         4          1  ...           NaN            NaN\n",
              "4         5          1  ...           NaN            NaN\n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grxem-X6l3rQ"
      },
      "source": [
        "df_test = pd.read_csv('test_set.tsv', sep='\\t', encoding='ISO-8859-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "afCKVjh5l-Su",
        "outputId": "38d97902-4943-42a9-ff1f-5d38fd347db7"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_predictionid</th>\n",
              "      <th>domain2_predictionid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2383</td>\n",
              "      <td>1</td>\n",
              "      <td>I believe that computers have a positive effec...</td>\n",
              "      <td>2383</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2384</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1, I know some problems have came up...</td>\n",
              "      <td>2384</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2385</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear to whom it @MONTH1 concern, Computers are...</td>\n",
              "      <td>2385</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2386</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, @CAPS3 has come to my atte...</td>\n",
              "      <td>2386</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2387</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local newspaper, I think that people have...</td>\n",
              "      <td>2387</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set  ... domain1_predictionid  domain2_predictionid\n",
              "0      2383          1  ...                 2383                   NaN\n",
              "1      2384          1  ...                 2384                   NaN\n",
              "2      2385          1  ...                 2385                   NaN\n",
              "3      2386          1  ...                 2386                   NaN\n",
              "4      2387          1  ...                 2387                   NaN\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb_bmAQZmKqq"
      },
      "source": [
        "#df_test.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhfMHVbOmm32"
      },
      "source": [
        "#df_train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImxWqWt1m4Oc"
      },
      "source": [
        "#df_train.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9SLLMNJnNax"
      },
      "source": [
        "df_train.dropna(axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "UjfPASALnQSq",
        "outputId": "40d4ab33-9a23-4cbd-d096-e922e13c371f"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>domain1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set  ... rater2_domain1  domain1_score\n",
              "0         1          1  ...              4              8\n",
              "1         2          1  ...              4              9\n",
              "2         3          1  ...              3              7\n",
              "3         4          1  ...              5             10\n",
              "4         5          1  ...              4              8\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLdJAKvEnbuX"
      },
      "source": [
        "#df_train.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn3GOZWRn8Yv"
      },
      "source": [
        "#print(df_train['essay_set'].nunique())\n",
        "#df_train['essay_set'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAmIr2smoHr1"
      },
      "source": [
        "#print(df_train.groupby('essay_set').size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu-UNlRGoQUH"
      },
      "source": [
        "#print(df_train['rater1_domain1'].nunique())\n",
        "#df_train['rater1_domain1'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq8WLWVVotm-"
      },
      "source": [
        "#print(df_train.groupby('rater1_domain1').size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HeX6EPdo14H"
      },
      "source": [
        "Note : None of the essay got 29 as rater1_domain1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L9z5O8KpAs0"
      },
      "source": [
        "#print(df_train['rater2_domain1'].nunique())\n",
        "#df_train['rater2_domain1'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CWal1dWpFYQ"
      },
      "source": [
        "#print(df_train.groupby('rater1_domain1').size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAYydc0fpQyU"
      },
      "source": [
        "#df_train['domain1_score'].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUHTun-kpYeQ"
      },
      "source": [
        "#df_train['domain1_score'].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrSAGczY31EN"
      },
      "source": [
        "#Numerical Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2SQcTPALUm0"
      },
      "source": [
        "def remove_it(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = re.sub('@', '', text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIHeB842LhOT"
      },
      "source": [
        "df_train['essay'] = df_train['essay'].apply(lambda x: remove_it(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTtW5hWdXqqc"
      },
      "source": [
        "temporary_2 = df_train.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "F7hhB3w-LqUX",
        "outputId": "11ef5675-8809-45d8-a5f4-048a4b734a30"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>domain1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>dear local newspaper, i think effects computer...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>dear  , i believe that using computers will be...</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>dear,    more and more people use computers, b...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>dear local newspaper,  i have found that many ...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>dear , i know having computers has a positive ...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set  ... rater2_domain1  domain1_score\n",
              "0         1          1  ...              4              8\n",
              "1         2          1  ...              4              9\n",
              "2         3          1  ...              3              7\n",
              "3         4          1  ...              5             10\n",
              "4         5          1  ...              4              8\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "-TJgNEPvL318",
        "outputId": "c4413cee-cc36-43b7-f83c-fb7729ba0130"
      },
      "source": [
        "df_train['essay'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"dear local newspaper, i think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! thing about! dont you think so? how would you feel if your teenager is always on the phone with friends! do you ever time to chat with your friends or buisness partner about things. well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: , , , facebook, myspace ect. just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. how did you learn about other countrys/states outside of yours? well i have by computer/internet, it's a new way to learn about what going on in our time! you might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the 's you'll be surprise at how much he/she knows. believe it or not the computer is much interesting then in class all day reading out of books. if your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. you might not know where your child is,  forbidde in a hospital bed because of a drive-by. rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. now i hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. thank you for listening.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FihG1DU4Ukep"
      },
      "source": [
        "def remove_it_1(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "\n",
        "    remove = string.punctuation\n",
        "    remove = remove.replace(\".\",\"\")\n",
        "    remove = remove.replace(\"?\",\"\")\n",
        "    remove = remove.replace(\"!\",\"\")\n",
        "\n",
        "    text = re.sub('[%s]' % re.escape(remove), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDKCd84nU5ER"
      },
      "source": [
        "temporary_2['essay'] = temporary_2['essay'].apply(lambda x: remove_it_1(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpmkiYFeuTEG"
      },
      "source": [
        "df_train_2 = temporary_2['essay'].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km0i6HhUD8it"
      },
      "source": [
        "df_train_1 = temporary_2['essay'].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "bR6SS97ORAj3",
        "outputId": "6a72a913-6849-4f90-f5e6-5cb6c0a3c048"
      },
      "source": [
        "df_train_1[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dear local newspaper i think effects computers have on people are great learning skillsaffects because they give us time to chat with friendsnew people helps us learn about the globeastronomy and keeps us out of troble! thing about! dont you think so? how would you feel if your teenager is always on the phone with friends! do you ever time to chat with your friends or buisness partner about things. well now  theres a new way to chat the computer theirs plenty of sites on the internet to do so    facebook myspace ect. just think now while your setting up meeting with your boss on the computer your teenager is having fun on the phone not rushing to get off cause you want to use it. how did you learn about other countrysstates outside of yours? well i have by computerinternet its a new way to learn about what going on in our time! you might think your child spends a lot of time on the computer but ask them so question about the economy sea floor spreading or even about the s youll be surprise at how much heshe knows. believe it or not the computer is much interesting then in class all day reading out of books. if your child is home on your computer or at a local library its better than being out with friends being fresh or being perpressured to doing something they know isnt right. you might not know where your child is  forbidde in a hospital bed because of a driveby. rather than your child on the computer learning chatting or just playing games safe and sound in your home or community place. now i hope you have reached a point to understand and agree with me because computers can have great effects on you or child because it gives us time to chat with friendsnew people helps us learn about the globe and believe or not keeps us out of troble. thank you for listening.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "kuG-dksxbjOH",
        "outputId": "3bb76753-9583-4455-a32f-881e850370b5"
      },
      "source": [
        "df_train_2[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dear local newspaper i think effects computers have on people are great learning skillsaffects because they give us time to chat with friendsnew people helps us learn about the globeastronomy and keeps us out of troble! thing about! dont you think so? how would you feel if your teenager is always on the phone with friends! do you ever time to chat with your friends or buisness partner about things. well now  theres a new way to chat the computer theirs plenty of sites on the internet to do so    facebook myspace ect. just think now while your setting up meeting with your boss on the computer your teenager is having fun on the phone not rushing to get off cause you want to use it. how did you learn about other countrysstates outside of yours? well i have by computerinternet its a new way to learn about what going on in our time! you might think your child spends a lot of time on the computer but ask them so question about the economy sea floor spreading or even about the s youll be surprise at how much heshe knows. believe it or not the computer is much interesting then in class all day reading out of books. if your child is home on your computer or at a local library its better than being out with friends being fresh or being perpressured to doing something they know isnt right. you might not know where your child is  forbidde in a hospital bed because of a driveby. rather than your child on the computer learning chatting or just playing games safe and sound in your home or community place. now i hope you have reached a point to understand and agree with me because computers can have great effects on you or child because it gives us time to chat with friendsnew people helps us learn about the globe and believe or not keeps us out of troble. thank you for listening.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYlbb3rqFeYm"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "for i in range(0,len(df_train_1)):\n",
        "  text = df_train_1[i]\n",
        "  text = sent_tokenize(text)\n",
        "  df_train_1[i] = text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UbEsFJIFF54",
        "outputId": "6a7e6a4e-ecbe-4f83-e87b-02b2e882fde5"
      },
      "source": [
        "df_train_1[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dear local newspaper i think effects computers have on people are great learning skillsaffects because they give us time to chat with friendsnew people helps us learn about the globeastronomy and keeps us out of troble!',\n",
              " 'thing about!',\n",
              " 'dont you think so?',\n",
              " 'how would you feel if your teenager is always on the phone with friends!',\n",
              " 'do you ever time to chat with your friends or buisness partner about things.',\n",
              " 'well now  theres a new way to chat the computer theirs plenty of sites on the internet to do so    facebook myspace ect.',\n",
              " 'just think now while your setting up meeting with your boss on the computer your teenager is having fun on the phone not rushing to get off cause you want to use it.',\n",
              " 'how did you learn about other countrysstates outside of yours?',\n",
              " 'well i have by computerinternet its a new way to learn about what going on in our time!',\n",
              " 'you might think your child spends a lot of time on the computer but ask them so question about the economy sea floor spreading or even about the s youll be surprise at how much heshe knows.',\n",
              " 'believe it or not the computer is much interesting then in class all day reading out of books.',\n",
              " 'if your child is home on your computer or at a local library its better than being out with friends being fresh or being perpressured to doing something they know isnt right.',\n",
              " 'you might not know where your child is  forbidde in a hospital bed because of a driveby.',\n",
              " 'rather than your child on the computer learning chatting or just playing games safe and sound in your home or community place.',\n",
              " 'now i hope you have reached a point to understand and agree with me because computers can have great effects on you or child because it gives us time to chat with friendsnew people helps us learn about the globe and believe or not keeps us out of troble.',\n",
              " 'thank you for listening.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS1r8_4XMqSJ"
      },
      "source": [
        "feature=pd.DataFrame(data=None, columns=['sentence','comma','exclamation','bracket','punctuation','quotation','word','word_length','long_word','verb','adverb','noun','pronoun','adjective','foreign','wrong_spell'])\n",
        " \n",
        "feature['comma'] = df_train.essay.str.count(\",\") \n",
        "feature['exclamation'] = df_train.essay.str.count(\"\\!\") \n",
        "feature['bracket'] = 0.5*df_train.essay.str.count(\"\\(|\\)\")\n",
        "feature['punctuation'] = df_train.essay.str.count('[%s]' % re.escape(string.punctuation))\n",
        "feature['quotation'] = 0.5*df_train.essay.str.count(\"\\\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pPOper6xz9E"
      },
      "source": [
        "for i in range(0,len(df_train_1)):\n",
        "  feature.at[i,'sentence'] = len(df_train_1[i])\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSx6-tBT0QdE"
      },
      "source": [
        "#DATA CLEANING(10 minutes completion time)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_zEWU9DsOkq"
      },
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krV1RoNVsTu3"
      },
      "source": [
        "df_train['essay'] = df_train['essay'].apply(lambda x: clean_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWLc8465sYHC",
        "outputId": "32ad4ee3-96d8-4562-d9a0-24baac5f7750"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>domain1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>dear local newspaper i think effects computers...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>dear   i believe that using computers will ben...</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>dear    more and more people use computers but...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>dear local newspaper  i have found that many e...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>dear  i know having computers has a positive e...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set  ... rater2_domain1  domain1_score\n",
              "0         1          1  ...              4              8\n",
              "1         2          1  ...              4              9\n",
              "2         3          1  ...              3              7\n",
              "3         4          1  ...              5             10\n",
              "4         5          1  ...              4              8\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1656
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux5PB6nisr1T"
      },
      "source": [
        "df_test['essay'] = df_test['essay'].apply(lambda x: clean_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3obfQjPl4bkz",
        "outputId": "7f465f9f-72d4-4c02-9b6b-03ef969a9c28"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_predictionid</th>\n",
              "      <th>domain2_predictionid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2383</td>\n",
              "      <td>1</td>\n",
              "      <td>i believe that computers have a positive effec...</td>\n",
              "      <td>2383</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2384</td>\n",
              "      <td>1</td>\n",
              "      <td>dear  i know some problems have came up where ...</td>\n",
              "      <td>2384</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2385</td>\n",
              "      <td>1</td>\n",
              "      <td>dear to whom it  concern computers arent the r...</td>\n",
              "      <td>2385</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2386</td>\n",
              "      <td>1</td>\n",
              "      <td>dear    has come to my attention that some peo...</td>\n",
              "      <td>2386</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2387</td>\n",
              "      <td>1</td>\n",
              "      <td>dear local newspaper i think that people have ...</td>\n",
              "      <td>2387</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set  ... domain1_predictionid  domain2_predictionid\n",
              "0      2383          1  ...                 2383                   NaN\n",
              "1      2384          1  ...                 2384                   NaN\n",
              "2      2385          1  ...                 2385                   NaN\n",
              "3      2386          1  ...                 2386                   NaN\n",
              "4      2387          1  ...                 2387                   NaN\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1658
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5riZJ_htKaG"
      },
      "source": [
        "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
        "\n",
        "# Tokenizing the training set\n",
        "df_train['essay'] = df_train['essay'].apply(lambda x: tokenizer.tokenize(x))\n",
        "\n",
        "# Tokenizing the test set\n",
        "df_test['essay'] = df_test['essay'].apply(lambda x: tokenizer.tokenize(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXi2vZ26tPWM",
        "outputId": "409e4c82-cb76-41f1-e702-ceddad99a6d7"
      },
      "source": [
        "print()\n",
        "print('Tokenized String:')\n",
        "df_train['essay'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Tokenized String:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [dear, local, newspaper, i, think, effects, co...\n",
              "1    [dear, i, believe, that, using, computers, wil...\n",
              "2    [dear, more, and, more, people, use, computers...\n",
              "3    [dear, local, newspaper, i, have, found, that,...\n",
              "4    [dear, i, know, having, computers, has, a, pos...\n",
              "Name: essay, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1660
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ3Je0nFtW0q",
        "outputId": "c75a1883-8d2b-44c7-a7b1-f5de36e13888"
      },
      "source": [
        "print()\n",
        "print('Tokenized String:')\n",
        "df_test['essay'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Tokenized String:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [i, believe, that, computers, have, a, positiv...\n",
              "1    [dear, i, know, some, problems, have, came, up...\n",
              "2    [dear, to, whom, it, concern, computers, arent...\n",
              "3    [dear, has, come, to, my, attention, that, som...\n",
              "4    [dear, local, newspaper, i, think, that, peopl...\n",
              "Name: essay, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1661
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm6Cs4rftbx_"
      },
      "source": [
        "def remove_stopwords(text):\n",
        "    \n",
        "    words = [word for word in text if word not in stopwords.words('english')]\n",
        "    return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPUjZbYctf8g"
      },
      "source": [
        "df_train['essay'] = df_train['essay'].apply(lambda x: remove_stopwords(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBv-PT6vvSep"
      },
      "source": [
        "df_test['essay'] = df_test['essay'].apply(lambda x: remove_stopwords(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOnFP-scvvwF",
        "outputId": "97706672-4b19-47d2-fa5c-f39e6cc8f8e8"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>domain1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[dear, local, newspaper, think, effects, compu...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>[dear, believe, using, computers, benefit, us,...</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>[dear, people, use, computers, everyone, agree...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>[dear, local, newspaper, found, many, experts,...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>[dear, know, computers, positive, effect, peop...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set  ... rater2_domain1  domain1_score\n",
              "0         1          1  ...              4              8\n",
              "1         2          1  ...              4              9\n",
              "2         3          1  ...              3              7\n",
              "3         4          1  ...              5             10\n",
              "4         5          1  ...              4              8\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1665
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOnsDCRMv0dI",
        "outputId": "cec9c6d9-66a3-468f-b8cd-f4024cfd0cc4"
      },
      "source": [
        "df_test.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_predictionid</th>\n",
              "      <th>domain2_predictionid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2383</td>\n",
              "      <td>1</td>\n",
              "      <td>[believe, computers, positive, effect, people,...</td>\n",
              "      <td>2383</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2384</td>\n",
              "      <td>1</td>\n",
              "      <td>[dear, know, problems, came, individuals, agre...</td>\n",
              "      <td>2384</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2385</td>\n",
              "      <td>1</td>\n",
              "      <td>[dear, concern, computers, arent, reason, peop...</td>\n",
              "      <td>2385</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2386</td>\n",
              "      <td>1</td>\n",
              "      <td>[dear, come, attention, people, believe, techn...</td>\n",
              "      <td>2386</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2387</td>\n",
              "      <td>1</td>\n",
              "      <td>[dear, local, newspaper, think, people, lately...</td>\n",
              "      <td>2387</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set  ... domain1_predictionid  domain2_predictionid\n",
              "0      2383          1  ...                 2383                   NaN\n",
              "1      2384          1  ...                 2384                   NaN\n",
              "2      2385          1  ...                 2385                   NaN\n",
              "3      2386          1  ...                 2386                   NaN\n",
              "4      2387          1  ...                 2387                   NaN\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1666
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLCUFJ6m-RLx"
      },
      "source": [
        "df_test.to_csv('clean_test_set.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1bRSg8y5Fob",
        "outputId": "0538d267-c3e2-4c8f-d42e-d7ca0cf1ebae"
      },
      "source": [
        "file1=pd.read_csv('clean_test_set.csv')\n",
        "file1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>domain1_predictionid</th>\n",
              "      <th>domain2_predictionid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2383</td>\n",
              "      <td>1</td>\n",
              "      <td>['believe', 'computers', 'positive', 'effect',...</td>\n",
              "      <td>2383</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2384</td>\n",
              "      <td>1</td>\n",
              "      <td>['dear', 'know', 'problems', 'came', 'individu...</td>\n",
              "      <td>2384</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2385</td>\n",
              "      <td>1</td>\n",
              "      <td>['dear', 'concern', 'computers', 'arent', 'rea...</td>\n",
              "      <td>2385</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2386</td>\n",
              "      <td>1</td>\n",
              "      <td>['dear', 'come', 'attention', 'people', 'belie...</td>\n",
              "      <td>2386</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2387</td>\n",
              "      <td>1</td>\n",
              "      <td>['dear', 'local', 'newspaper', 'think', 'peopl...</td>\n",
              "      <td>2387</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set  ... domain1_predictionid  domain2_predictionid\n",
              "0      2383          1  ...                 2383                   NaN\n",
              "1      2384          1  ...                 2384                   NaN\n",
              "2      2385          1  ...                 2385                   NaN\n",
              "3      2386          1  ...                 2386                   NaN\n",
              "4      2387          1  ...                 2387                   NaN\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1668
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iea6NETJBd1Q"
      },
      "source": [
        "df_train.to_csv('clean_train_set.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOdxcKq3BxoP",
        "outputId": "035c16d2-f253-46e2-ae9c-07d39200980f"
      },
      "source": [
        "file=pd.read_csv('clean_train_set.csv')\n",
        "file.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>domain1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>['dear', 'local', 'newspaper', 'think', 'effec...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>['dear', 'believe', 'using', 'computers', 'ben...</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>['dear', 'people', 'use', 'computers', 'everyo...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>['dear', 'local', 'newspaper', 'found', 'many'...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>['dear', 'know', 'computers', 'positive', 'eff...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   essay_id  essay_set  ... rater2_domain1  domain1_score\n",
              "0         1          1  ...              4              8\n",
              "1         2          1  ...              4              9\n",
              "2         3          1  ...              3              7\n",
              "3         4          1  ...              5             10\n",
              "4         5          1  ...              4              8\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1670
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k--YqYrTVSnl"
      },
      "source": [
        "#Feature Extraction(4 minutes completion time)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7__tcQjzMWg"
      },
      "source": [
        "feature['word'] = [len(x.split()) for x in file['essay'].tolist()]\n",
        "feature['word_length'] = file.essay.apply(len)/feature['word']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSPB8TzOhngQ"
      },
      "source": [
        "average = feature.mean(axis=0, skipna=True)['word_length']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LojOc6eSYnqJ"
      },
      "source": [
        "list1 = file['essay'].str.split(',|\\ |\\[|\\]|\\'')\n",
        "\n",
        "for i in range(0,len(list1)):\n",
        "  list1[i] = [x for x in list1[i] if x!='']\n",
        "\n",
        "for k in range(0,len(list1)):\n",
        "    count=0\n",
        "    for j in range(0,len(list1[k])):\n",
        "        if(len(list1[k][j])>=average):\n",
        "            count = count + 1\n",
        "    feature.at[k,'long_word']=count     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_RwiykNEaQO"
      },
      "source": [
        "\n",
        "for i in range(0,len(df_train_1)):\n",
        "    noun = 0\n",
        "    pronoun = 0\n",
        "    verb = 0\n",
        "    adverb = 0\n",
        "    adjective = 0\n",
        "    foreign = 0\n",
        "\n",
        "    for j in range(0,len(df_train_1[i])):\n",
        "\n",
        "        tokens = nltk.word_tokenize(df_train_1[i][j])\n",
        "        t=nltk.pos_tag(tokens)\n",
        "\n",
        "        for ii in range(0,len(t)):\n",
        "           if t[ii][1][0] == 'N':\n",
        "              noun = noun + 1\n",
        "           if t[ii][1][0] == 'P' and t[ii][1][1] == 'R':\n",
        "              pronoun = pronoun + 1\n",
        "           if t[ii][1][0] == 'V':\n",
        "              verb = verb + 1\n",
        "           if t[ii][1][0] == 'R' and t[ii][1][1] == 'B':\n",
        "              adverb = adverb + 1\n",
        "           if t[ii][1][0] == 'J':\n",
        "              adjective = adjective + 1\n",
        "           if t[ii][1][0] == 'F':\n",
        "              foreign = foreign + 1\n",
        "\n",
        "    feature.at[i,'noun'] = noun\n",
        "    feature.at[i,'pronoun'] = pronoun\n",
        "    feature.at[i,'verb'] = verb\n",
        "    feature.at[i,'adverb'] = adverb\n",
        "    feature.at[i,'adjective'] = adjective\n",
        "    feature.at[i,'foreign'] = foreign\n",
        "                 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzTg5KYqLb2j"
      },
      "source": [
        "spell = SpellChecker()\n",
        "\n",
        "for i in range(0,len(df_train['essay'])):\n",
        "    misspelled = spell.unknown(df_train['essay'][i])\n",
        "    feature.at[i,'wrong_spell'] =len(misspelled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "8fijqzXWSyVS",
        "outputId": "612340e1-dd79-4dfa-9fb2-bf309be73d95"
      },
      "source": [
        "feature.iloc[0:10,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>comma</th>\n",
              "      <th>exclamation</th>\n",
              "      <th>bracket</th>\n",
              "      <th>punctuation</th>\n",
              "      <th>quotation</th>\n",
              "      <th>word</th>\n",
              "      <th>word_length</th>\n",
              "      <th>long_word</th>\n",
              "      <th>verb</th>\n",
              "      <th>adverb</th>\n",
              "      <th>noun</th>\n",
              "      <th>pronoun</th>\n",
              "      <th>adjective</th>\n",
              "      <th>foreign</th>\n",
              "      <th>wrong_spell</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>158</td>\n",
              "      <td>9.791139</td>\n",
              "      <td>9</td>\n",
              "      <td>71</td>\n",
              "      <td>22</td>\n",
              "      <td>75</td>\n",
              "      <td>37</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216</td>\n",
              "      <td>9.671296</td>\n",
              "      <td>11</td>\n",
              "      <td>86</td>\n",
              "      <td>15</td>\n",
              "      <td>100</td>\n",
              "      <td>35</td>\n",
              "      <td>19</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>14</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>27</td>\n",
              "      <td>0.0</td>\n",
              "      <td>132</td>\n",
              "      <td>10.053030</td>\n",
              "      <td>6</td>\n",
              "      <td>48</td>\n",
              "      <td>14</td>\n",
              "      <td>77</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50</td>\n",
              "      <td>1.5</td>\n",
              "      <td>259</td>\n",
              "      <td>10.250965</td>\n",
              "      <td>16</td>\n",
              "      <td>94</td>\n",
              "      <td>28</td>\n",
              "      <td>135</td>\n",
              "      <td>21</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>221</td>\n",
              "      <td>9.968326</td>\n",
              "      <td>11</td>\n",
              "      <td>90</td>\n",
              "      <td>33</td>\n",
              "      <td>109</td>\n",
              "      <td>27</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21</td>\n",
              "      <td>0.0</td>\n",
              "      <td>101</td>\n",
              "      <td>9.623762</td>\n",
              "      <td>7</td>\n",
              "      <td>48</td>\n",
              "      <td>16</td>\n",
              "      <td>50</td>\n",
              "      <td>24</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>30</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>74</td>\n",
              "      <td>0.0</td>\n",
              "      <td>251</td>\n",
              "      <td>9.900398</td>\n",
              "      <td>11</td>\n",
              "      <td>81</td>\n",
              "      <td>37</td>\n",
              "      <td>126</td>\n",
              "      <td>52</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>39</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79</td>\n",
              "      <td>1.0</td>\n",
              "      <td>243</td>\n",
              "      <td>9.897119</td>\n",
              "      <td>18</td>\n",
              "      <td>111</td>\n",
              "      <td>25</td>\n",
              "      <td>113</td>\n",
              "      <td>38</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>35</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65</td>\n",
              "      <td>1.5</td>\n",
              "      <td>216</td>\n",
              "      <td>9.708333</td>\n",
              "      <td>13</td>\n",
              "      <td>82</td>\n",
              "      <td>30</td>\n",
              "      <td>106</td>\n",
              "      <td>29</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>26</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228</td>\n",
              "      <td>9.429825</td>\n",
              "      <td>11</td>\n",
              "      <td>104</td>\n",
              "      <td>30</td>\n",
              "      <td>104</td>\n",
              "      <td>35</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentence  comma  exclamation  bracket  ...  pronoun  adjective  foreign  wrong_spell\n",
              "0       16     18            4      1.0  ...       37         19        0           10\n",
              "1       20     12            1      0.0  ...       35         19        1            9\n",
              "2       14      9            0      0.0  ...       13         20        0            0\n",
              "3       27     13            2      0.0  ...       21         40        0           17\n",
              "4       30     13            0      0.0  ...       27         28        0            9\n",
              "5       15      3            1      0.0  ...       24         10        0            5\n",
              "6       30     35            0      0.0  ...       52         28        0            1\n",
              "7       39     11            1      0.0  ...       38         36        0            2\n",
              "8       35     16            1      0.0  ...       29         32        0            1\n",
              "9       26     14            0      0.0  ...       35         41        0            4\n",
              "\n",
              "[10 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1676
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxR2lTzVS3_W",
        "outputId": "686788a5-1dba-46a4-fa7a-870d55c276f0"
      },
      "source": [
        "feature.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12976 entries, 0 to 12975\n",
            "Data columns (total 16 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   sentence     12976 non-null  object \n",
            " 1   comma        12976 non-null  int64  \n",
            " 2   exclamation  12976 non-null  int64  \n",
            " 3   bracket      12976 non-null  float64\n",
            " 4   punctuation  12976 non-null  int64  \n",
            " 5   quotation    12976 non-null  float64\n",
            " 6   word         12976 non-null  int64  \n",
            " 7   word_length  12976 non-null  float64\n",
            " 8   long_word    12976 non-null  object \n",
            " 9   verb         12976 non-null  object \n",
            " 10  adverb       12976 non-null  object \n",
            " 11  noun         12976 non-null  object \n",
            " 12  pronoun      12976 non-null  object \n",
            " 13  adjective    12976 non-null  object \n",
            " 14  foreign      12976 non-null  object \n",
            " 15  wrong_spell  12976 non-null  object \n",
            "dtypes: float64(3), int64(4), object(9)\n",
            "memory usage: 1.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnJUBR-eTJA9"
      },
      "source": [
        "feature.to_csv('dataset.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Mu60veu74qG"
      },
      "source": [
        "#NLP Advanced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhsJspk8sfgR"
      },
      "source": [
        "from nltk.stem import SnowballStemmer \n",
        "stemmer = SnowballStemmer(\"english\",ignore_stopwords=True)\n",
        "\n",
        "\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "\n",
        "def stemming_text(text):\n",
        "     return [\" \".join(stemmer.stem(w) for w in w_tokenizer.tokenize(text))]\n",
        "\n",
        "df_train_2 = df_train_2.apply(stemming_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_c_rRF34oLq"
      },
      "source": [
        "def listToString(s):  \n",
        "    \n",
        "    # initialize an empty string \n",
        "    str1 = \"\"  \n",
        "    \n",
        "    # traverse in the string   \n",
        "    for ele in s:  \n",
        "        str1 += ele   \n",
        "    \n",
        "    # return string   \n",
        "    return str1  \n",
        "        \n",
        "        \n",
        "df_train_2 = df_train_2.apply(listToString)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "VVqUkUpPzP3h",
        "outputId": "842464f8-bb4a-4dc1-9e84-c661b91e7e97"
      },
      "source": [
        "df_train_2[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dear local newspap i think effect comput have on peopl are great learn skillsaffect because they give us time to chat with friendsnew peopl help us learn about the globeastronomi and keep us out of troble! thing about! dont you think so? how would you feel if your teenag is alway on the phone with friends! do you ever time to chat with your friend or buis partner about things. well now there a new way to chat the comput theirs plenti of site on the internet to do so facebook myspac ect. just think now while your set up meet with your boss on the comput your teenag is having fun on the phone not rush to get off caus you want to use it. how did you learn about other countrysst outsid of yours? well i have by computerinternet its a new way to learn about what go on in our time! you might think your child spend a lot of time on the comput but ask them so question about the economi sea floor spread or even about the s youll be surpris at how much hesh knows. believ it or not the comput is much interest then in class all day read out of books. if your child is home on your comput or at a local librari its better than being out with friend being fresh or being perpressur to doing someth they know isnt right. you might not know where your child is forbidd in a hospit bed because of a driveby. rather than your child on the comput learn chat or just play game safe and sound in your home or communiti place. now i hope you have reach a point to understand and agre with me because comput can have great effect on you or child because it give us time to chat with friendsnew peopl help us learn about the globe and believ or not keep us out of troble. thank you for listening.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQVbtUuK9Rr1"
      },
      "source": [
        "feature = pd.read_csv('dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T90bWpPs7-Ud"
      },
      "source": [
        "set_array = np.array([0,1785,3585,5311,7081,8886,10686,12255,12978])\n",
        "\n",
        "tfidf = CountVectorizer(max_df=0.8,min_df=0.0,ngram_range=(1,3),stop_words='english',max_features=60)\n",
        "\n",
        "for i in range(0,8):\n",
        "\n",
        "    tr = tfidf.fit_transform(df_train_2[set_array[i]:set_array[i+1]])\n",
        "\n",
        "    if i==0:\n",
        "      df_tfidf = pd.DataFrame(data=tr.toarray(),columns=tfidf.get_feature_names())\n",
        "\n",
        "    else:\n",
        "      tf_temp = pd.DataFrame(data=tr.toarray(),columns=tfidf.get_feature_names())\n",
        "      df_tfidf = df_tfidf.append(tf_temp,ignore_index=True)\n",
        "\n",
        "    if i==7:\n",
        "      # feata = pd.DataFrame(data=feature[12255:12978][:].to_numpy(),index=list(range(0,721)))\n",
        "      feature = pd.concat([feature,df_tfidf], axis=1)\n",
        "      # feature = df_tfidf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "5cskWS7A8Fnq",
        "outputId": "5f7656ed-0945-4ad2-f14d-8dc865a7c5c0"
      },
      "source": [
        "feature = feature.fillna(0)\n",
        "feature.iloc[6060:6070,170:200]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>end stori</th>\n",
              "      <th>fail</th>\n",
              "      <th>flower</th>\n",
              "      <th>gees</th>\n",
              "      <th>gees return</th>\n",
              "      <th>gees return hibiscus</th>\n",
              "      <th>hibiscus</th>\n",
              "      <th>hibiscus bud</th>\n",
              "      <th>hibiscus bud test</th>\n",
              "      <th>home</th>\n",
              "      <th>melt</th>\n",
              "      <th>melt gees</th>\n",
              "      <th>melt gees return</th>\n",
              "      <th>mother</th>\n",
              "      <th>paragraph</th>\n",
              "      <th>pass</th>\n",
              "      <th>plant</th>\n",
              "      <th>reader</th>\n",
              "      <th>return</th>\n",
              "      <th>return hibiscus</th>\n",
              "      <th>return hibiscus bud</th>\n",
              "      <th>saeng</th>\n",
              "      <th>snow</th>\n",
              "      <th>snow melt</th>\n",
              "      <th>snow melt gees</th>\n",
              "      <th>spring</th>\n",
              "      <th>spring snow</th>\n",
              "      <th>spring snow melt</th>\n",
              "      <th>start</th>\n",
              "      <th>stori paragraph</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6060</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6061</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6062</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6063</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6064</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6065</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6066</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6067</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6068</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6069</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      end stori  fail  flower  ...  spring snow melt  start  stori paragraph\n",
              "6060        0.0   0.0     1.0  ...               0.0    1.0              1.0\n",
              "6061        0.0   0.0     0.0  ...               0.0    0.0              1.0\n",
              "6062        1.0   1.0     1.0  ...               0.0    0.0              1.0\n",
              "6063        1.0   1.0     0.0  ...               0.0    0.0              0.0\n",
              "6064        0.0   0.0     0.0  ...               0.0    0.0              1.0\n",
              "6065        0.0   1.0     0.0  ...               0.0    0.0              2.0\n",
              "6066        1.0   0.0     0.0  ...               0.0    2.0              0.0\n",
              "6067        0.0   0.0     0.0  ...               0.0    0.0              0.0\n",
              "6068        1.0   0.0     0.0  ...               0.0    0.0              1.0\n",
              "6069        1.0   0.0     0.0  ...               0.0    0.0              0.0\n",
              "\n",
              "[10 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaGCDsQ_8JPF",
        "outputId": "a3f4831f-2027-41dc-e739-f81d4a1e1cd3"
      },
      "source": [
        "feature.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12976, 342)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWTV1Xs09anl"
      },
      "source": [
        "feature.to_csv('main_dataset.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uu_8M7gZUiO"
      },
      "source": [
        "#Polynomial Regression Model(SET WISE)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93GPhx2Fcmzw"
      },
      "source": [
        "set_ = np.array([0,1785,3585,5311,7081,8886,10686,12255,12978])\n",
        "set_1=0\n",
        "set_2=1785\n",
        "set_3=3585\n",
        "set_4=5311\n",
        "set_5=7081\n",
        "set_6=8886\n",
        "set_7=10686\n",
        "set_8=12255\n",
        "end=12978\n",
        "j=6                       # j=2 means set number 3."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yNUXf0_Tqpz"
      },
      "source": [
        "X = pd.read_csv('main_dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEDUgTSm-ccl"
      },
      "source": [
        "graph = X['adjective'][set_1:end].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-hKSh9z4FVW"
      },
      "source": [
        "X = minmax_scaling(X, columns = X.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXI-cUQDZh4r"
      },
      "source": [
        "X = X.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkvVtwySUbJ9"
      },
      "source": [
        "y = pd.read_csv('clean_train_set.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmfbAaAlUqJy"
      },
      "source": [
        "y = y['domain1_score'].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "4f2GFrGT-BON",
        "outputId": "c28012ad-1276-4783-bfa7-96f7c5a28b08"
      },
      "source": [
        "plt.scatter(y[set_1:end],graph)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f3f3fdb2550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZZeMpqN1OfF"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model\n",
        " \n",
        "column = ['Essay_set','Essay_number', 'Predicted', 'Actual']\n",
        " \n",
        "for i in range(0,8):\n",
        " \n",
        "     X1 = X[set_[i]:set_[i+1],:] \n",
        "     y1 = y[set_[i]:set_[i+1]]\n",
        " \n",
        "     #print(\"SET\",i+1,\"actual scores:\\n\\n\",y1[100:200],'\\n\\n') \n",
        " \n",
        "     x_train, x_test, y_train, y_test = train_test_split(X1, y1, test_size=0.15,random_state=50)\n",
        " \n",
        "     poly = PolynomialFeatures(degree=1)\n",
        "     x=poly.fit_transform(x_train)\n",
        " \n",
        "     clf = linear_model.LinearRegression()\n",
        "     clf.fit(x,y_train)\n",
        " \n",
        "     initial = 0\n",
        "     final = len(x_test)\n",
        "     predict_ = poly.fit_transform(x_test[initial:final,:])\n",
        " \n",
        "     \n",
        "     tempo = np.c_[ np.full((final-initial, 1), i+1) , initial + np.arange(final-initial), clf.predict(predict_) , y_test[initial:final] ]\n",
        "   \n",
        "     if i==0:  \n",
        "        result = np.c_[ np.full((final-initial, 1), i+1) , initial + np.arange(final-initial), clf.predict(predict_) , y_test[initial:final] ]\n",
        "     else:\n",
        "        result = np.append(result, tempo, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PflkTG2jOGUT"
      },
      "source": [
        "output_result = pd.DataFrame(data = result, columns = column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW7-hbnAQyEL",
        "outputId": "fddd90f5-052b-44b7-d08f-3547a333acdd"
      },
      "source": [
        "len(output_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1949"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nanS4gZYnzpQ"
      },
      "source": [
        "#Predict Here*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvABy8zp_WUE"
      },
      "source": [
        "answer = pd.DataFrame(data = None, columns = column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAd7NvCC9WMl"
      },
      "source": [
        "iii=0\n",
        "for i in range(0,len(output_result)):\n",
        "   if output_result['Essay_set'][i]==8.0:\n",
        "      answer.at[iii, 'Essay_set']=output_result['Essay_set'][i]\n",
        "      answer.at[iii, 'Essay_number']=output_result['Essay_number'][i]\n",
        "      answer.at[iii, 'Actual']=output_result['Actual'][i]\n",
        "      answer.at[iii, 'Predicted']=output_result['Predicted'][i]\n",
        "      iii=iii+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V95le4JVALJ-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "47f7629c-599c-4f1d-8bfd-88d0b9785d4a"
      },
      "source": [
        "answer[:][60:80]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay_set</th>\n",
              "      <th>Essay_number</th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>8</td>\n",
              "      <td>60</td>\n",
              "      <td>35.2747</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>8</td>\n",
              "      <td>61</td>\n",
              "      <td>40.1937</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>8</td>\n",
              "      <td>62</td>\n",
              "      <td>32.945</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>8</td>\n",
              "      <td>63</td>\n",
              "      <td>41.4126</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>8</td>\n",
              "      <td>64</td>\n",
              "      <td>30.453</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>8</td>\n",
              "      <td>65</td>\n",
              "      <td>40.1168</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>8</td>\n",
              "      <td>66</td>\n",
              "      <td>34.7089</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>8</td>\n",
              "      <td>67</td>\n",
              "      <td>34.5571</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>8</td>\n",
              "      <td>68</td>\n",
              "      <td>40.38</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>8</td>\n",
              "      <td>69</td>\n",
              "      <td>37.4909</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>8</td>\n",
              "      <td>70</td>\n",
              "      <td>30.5095</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>8</td>\n",
              "      <td>71</td>\n",
              "      <td>40.0129</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>8</td>\n",
              "      <td>72</td>\n",
              "      <td>38.4665</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>8</td>\n",
              "      <td>73</td>\n",
              "      <td>41.9022</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>8</td>\n",
              "      <td>74</td>\n",
              "      <td>47.825</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>8</td>\n",
              "      <td>75</td>\n",
              "      <td>31.9599</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>8</td>\n",
              "      <td>76</td>\n",
              "      <td>38.0812</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>8</td>\n",
              "      <td>77</td>\n",
              "      <td>44.164</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>8</td>\n",
              "      <td>78</td>\n",
              "      <td>38.2028</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>8</td>\n",
              "      <td>79</td>\n",
              "      <td>33.8136</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Essay_set Essay_number Predicted Actual\n",
              "60         8           60   35.2747     34\n",
              "61         8           61   40.1937     45\n",
              "62         8           62    32.945     33\n",
              "63         8           63   41.4126     40\n",
              "64         8           64    30.453     32\n",
              "65         8           65   40.1168     40\n",
              "66         8           66   34.7089     40\n",
              "67         8           67   34.5571     37\n",
              "68         8           68     40.38     40\n",
              "69         8           69   37.4909     46\n",
              "70         8           70   30.5095     36\n",
              "71         8           71   40.0129     40\n",
              "72         8           72   38.4665     37\n",
              "73         8           73   41.9022     40\n",
              "74         8           74    47.825     50\n",
              "75         8           75   31.9599     31\n",
              "76         8           76   38.0812     37\n",
              "77         8           77    44.164     50\n",
              "78         8           78   38.2028     36\n",
              "79         8           79   33.8136     32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THkapURbtBJK"
      },
      "source": [
        "RMSE = pd.DataFrame(data = None, columns = ['Essay_set','Marking_Scale','RMSE','Max_AE'])\n",
        " \n",
        "e_set = 1.0\n",
        "ind = 0\n",
        "rmse = 0.0\n",
        "index = 0\n",
        "max=0\n",
        " \n",
        "for i in range(0,len(output_result)):\n",
        " \n",
        "    if output_result['Essay_set'][i] == e_set + 1:\n",
        "        RMSE.at[index,'RMSE'] = math.sqrt(rmse/(len(output_result[0:i]) - len(output_result[0:ind])))\n",
        "        RMSE.at[index,'Essay_set'] = e_set\n",
        "        RMSE.at[index,'Max_AE'] = max  \n",
        "        rmse = 0.0\n",
        "        e_set = e_set + 1\n",
        "        asb=output_result['Actual'][i]-output_result['Predicted'][i]\n",
        "        rmse= rmse + asb*asb\n",
        "        ind = i\n",
        "        index = index + 1\n",
        "        max=abs(asb)\n",
        "        \n",
        "    asb=output_result['Actual'][i]-output_result['Predicted'][i]\n",
        "    rmse= rmse + asb*asb \n",
        " \n",
        "    if max<abs(asb):\n",
        "        max=abs(asb)\n",
        " \n",
        "RMSE.at[index,'RMSE'] = math.sqrt(rmse/(len(output_result[0:i]) - len(output_result[0:ind])))\n",
        "RMSE.at[index,'Essay_set'] = e_set\n",
        "RMSE.at[index,'Max_AE'] = max  \n",
        " \n",
        "RMSE['Marking_Scale'] = pd.Series(['2-12','1-5','0-3','0-3','0-4','0-4','0-30','0-60'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xqJlFv3Jc-C"
      },
      "source": [
        " \n",
        "c=0\n",
        "k=0\n",
        "e_set=1.0\n",
        "index=0\n",
        " for i in range(0,len(output_result)):\n",
        " \n",
        "   if output_result['Essay_set'][i] == e_set:\n",
        "      if abs(output_result['Predicted'][i]-output_result['Actual'][i])<=RMSE['RMSE'][index]:\n",
        "          c=c+1\n",
        "      k=k+1\n",
        " \n",
        "   else:\n",
        "      RMSE.at[index,'Agreement with RMSE'] = 100*c/k\n",
        "      index = index + 1\n",
        "      c=0\n",
        "      k=0\n",
        "      i=i-1\n",
        "      e_set=e_set+1\n",
        " \n",
        "RMSE.at[index,'Agreement with RMSE'] = 100*c/k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "vPORlD87OsK3",
        "outputId": "410c6f72-d82f-41ef-d239-4072a188dc11"
      },
      "source": [
        " RMSE[:][:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay_set</th>\n",
              "      <th>Marking_Scale</th>\n",
              "      <th>RMSE</th>\n",
              "      <th>Max_AE</th>\n",
              "      <th>Agreement with RMSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2-12</td>\n",
              "      <td>0.907016</td>\n",
              "      <td>3.90208</td>\n",
              "      <td>71.641791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1-5</td>\n",
              "      <td>0.566908</td>\n",
              "      <td>1.95505</td>\n",
              "      <td>68.773234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0-3</td>\n",
              "      <td>0.569914</td>\n",
              "      <td>1.94656</td>\n",
              "      <td>74.031008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0-3</td>\n",
              "      <td>0.645133</td>\n",
              "      <td>2.2733</td>\n",
              "      <td>72.075472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0-4</td>\n",
              "      <td>0.513809</td>\n",
              "      <td>1.74988</td>\n",
              "      <td>68.518519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0-4</td>\n",
              "      <td>0.574381</td>\n",
              "      <td>1.82212</td>\n",
              "      <td>66.914498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0-30</td>\n",
              "      <td>3.10101</td>\n",
              "      <td>9.24329</td>\n",
              "      <td>63.829787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0-60</td>\n",
              "      <td>3.56323</td>\n",
              "      <td>9.76179</td>\n",
              "      <td>69.444444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Essay_set Marking_Scale      RMSE   Max_AE  Agreement with RMSE\n",
              "0         1          2-12  0.907016  3.90208            71.641791\n",
              "1         2           1-5  0.566908  1.95505            68.773234\n",
              "2         3           0-3  0.569914  1.94656            74.031008\n",
              "3         4           0-3  0.645133   2.2733            72.075472\n",
              "4         5           0-4  0.513809  1.74988            68.518519\n",
              "5         6           0-4  0.574381  1.82212            66.914498\n",
              "6         7          0-30   3.10101  9.24329            63.829787\n",
              "7         8          0-60   3.56323  9.76179            69.444444"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    }
  ]
}